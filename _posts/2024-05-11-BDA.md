---
title: Base de Données INSEE
description: Modélisation et implémentation d'une base de données INSEE en PostgreSQL
author: <author_id>
date: 2024-05-11 11:33:00 +0800
categories: [Projet Universitaire, Base de Données]
tags: [projet, base de données, PostgreSQL, python, SQL]
pin: true
math: true
mermaid: true
---

# Modélisation et implémentation d'une base de données INSEE en PostgreSQL

## Introduction

Dans le cadre du cours de Base de Données Avancées, avec mon duo [Hamad Tria](https://github.com/HamadTria), nous avons réalisé un projet de modélisation et implémentation d'une base de données INSEE en PostgreSQL. Nous avons utilisé les données de l'INSEE pour modéliser une base de données relationnelle en PostgreSQL. Nous avons utilisé le langage python pour extraire les données de l'INSEE et les insérer dans la base de données PostgreSQL, à l'aide de la librairie psycopg2.

## Données INSEE et problématiques de modélisation

Nous avons utilisés plusieurs fichiers csv de l'INSEE pour extraire les données suivantes :
- Les données des communes, des départements et des régions de France Métropolitaine
- Les données de naissance, de décès, de recensement de la population, des logements et des ménages sur plusieurs années
- Les données de mariage pour une année

Les données de l'INSEE sont structurées en plusieurs fichiers csv, avec des données sur plusieurs années. Elles comportes quelques problèmes de structure pour les bases de données relationnelles. En effet, les données de l'INSEE sont structurées en plusieurs fichiers csv, avec des données sur plusieurs années. Chaque année de données est représentée par une colonne dans le fichier csv, ce qui rend difficile l'insertion des données dans une base de données relationnelle. Il était donc important de modéliser une base de données relationnelle qui permettrait de stocker les données de l'INSEE de manière efficace, sans avoir à modifier la structure de la base de données à chaque nouvelle année de données. 
Ainsi, nous avons modélisé une base de données relationnelle en PostgreSQL qui permet de stocker les données de l'INSEE de manière efficace, sans avoir à modifier la structure de la base de données à chaque nouvelle année de données.  

Voici un schéma de la base de données :

```mermaid
classDiagram
direction BT
class chef_lieu_departement {
   char id_chef_lieu
   varchar id_departement
}
class chef_lieu_region {
   char id_chef_lieu
   int id_region
}
class commune {
   varchar nom_commune
   double superf
   varchar id_departement
   char id_commune
}
class departement {
   varchar nom_departement
   int id_region
   varchar id_departement
}
class region {
   varchar nom_region
   int id_region
}
class statistiques_mariages_age {
   int nb_mariages
   int nb_mariages_premier
   int annee
   varchar typmar3
   int id_region
   varchar id_departement
   varchar grage
}
class statistiques_mariages_etat_matrimonial {
   int nbmaries
   int annee
   varchar typmar
   int id_region
   varchar id_departement
   char sexe
   char etamat
}
class statistiques_mariages_mensuel {
   int nbmar
   int annee
   varchar typmar2
   int id_region
   varchar id_departement
   char mmar
}
class statistiques_mariages_origine {
   int nb_mariages_nationalite
   int nb_mariages_pays_naissance
   int annee
   varchar typmar2
   int id_region
   varchar id_departement
   varchar code
}
class statistiques_population {
   int annee2
   double valeur
   varchar codgeo
   int annee
   varchar type_statistique
}

chef_lieu_departement  -->  commune : id_chef_lieu
chef_lieu_departement  -->  commune : id_commune
chef_lieu_departement  -->  departement : id_departement
chef_lieu_region  -->  commune : id_chef_lieu
chef_lieu_region  -->  commune : id_commune
chef_lieu_region  -->  region : id_region
commune  -->  departement : id_departement
departement  -->  region : id_region
statistiques_mariages_age  -->  departement : id_departement
statistiques_mariages_age  -->  region : id_region
statistiques_mariages_etat_matrimonial  -->  departement : id_departement
statistiques_mariages_etat_matrimonial  -->  region : id_region
statistiques_mariages_mensuel  -->  departement : id_departement
statistiques_mariages_mensuel  -->  region : id_region
statistiques_mariages_origine  -->  departement : id_departement
statistiques_mariages_origine  -->  region : id_region
statistiques_population  -->  commune : codgeo
statistiques_population  -->  commune : id_commune
```

## Connexion à la base de données PostgreSQL avec Python

Pour se connecter à la base de données PostgreSQL avec Python, nous avons utilisé la librairie psycopg2. Voici un exemple de code Python qui permet de se connecter à la base de données PostgreSQL :

```python
def connect():
    config = configparser.ConfigParser()
    config.read('config.ini')
    db_params = config['postgresql']
    try:
        conn = psycopg2.connect(**db_params)
        return conn
    except Exception as e:
        exit("Connexion impossible à la base de données: " + str(e))
```

Dans ce code, nous utilisons la librairie configparser pour lire les paramètres de connexion à la base de données PostgreSQL à partir d'un fichier de configuration config.ini. Nous utilisons ensuite la méthode connect de psycopg2 pour se connecter à la base de données PostgreSQL. Si la connexion à la base de données échoue, le programme affiche un message d'erreur et s'arrête.

Voici un exemple de fichier de configuration config.ini :

```
[postgresql]
host=localhost
dbname=database_name
user=username
password=3za2*HuuZD678%dDZx
```

Dans ce fichier de configuration, nous spécifions les paramètres de connexion à la base de données PostgreSQL, tels que l'hôte, le nom de la base de données, l'utilisateur et le mot de passe. Ces paramètres sont lus par le script Python pour se connecter à la base de données PostgreSQL. 

> Attention : Il est important de ne pas stocker les mots de passe en clair dans les fichiers de configuration. Il est recommandé d'utiliser des méthodes de chiffrement pour stocker les mots de passe de manière sécurisée, ici nous avons utilisé un mot de passe en clair à titre d'exemple.
{: .prompt-danger }

## Extraction et insertion des données

Pour l'extraction et l'insertion des données, nous avons utilisé le langage python et les libraries pandas et psycopg2. Nous avons créé un script python qui permet d'extraire les données des fichiers csv de l'INSEE et de les insérer dans la base de données PostgreSQL. Pour chaque type de données, nous avons créé une fonction python qui permet d'extraire les données du fichier csv et de les insérer dans la base de données PostgreSQL, pour une intervalle d'années donnée. Cela permet d'automatiser l'insertion des données dans la base de données PostgreSQL, sans avoir à modifier le script python à chaque nouvelle année de données.

Pour chaque table, nous créons un dataframe pandas dont la structure correspond à celle de la table dans la base de données PostgreSQL. Nous insérons ensuite les données du dataframe dans la base de données PostgreSQL à l'aide de la librairie psycopg2. Nous avons utilisé la méthode COPY de PostgreSQL pour insérer les données dans la base de données, ce qui permet d'insérer les données de manière efficace, sans avoir à insérer chaque ligne de données individuellement.

Voici la fonction python qui permet d'insérer un dataframe dans une table de la base de données PostgreSQL :

```python
def insert_dataframe_into_table(df, table_name, columns): 
    conn = connect()
    cur = conn.cursor()
    buffer = io.StringIO()
    df.to_csv(buffer, index=False, header=False)
    buffer.seek(0)
    copy_query = f"COPY {table_name} ({', '.join(columns)}) FROM STDIN WITH (FORMAT CSV);"
    cur.copy_expert(copy_query, buffer)
    conn.commit()
    print(f"Données insérées dans la table '{table_name}' avec succès")
    cur.close()
    conn.close()
```

Dans cette fonction, nous utilisons la méthode to_csv de pandas pour écrire les données du dataframe dans un buffer. Nous utilisons ensuite la méthode copy_expert de psycopg2 pour insérer les données du buffer dans la table de la base de données PostgreSQL. Nous spécifions le nom de la table et les colonnes de la table dans la requête COPY, ce qui permet d'insérer les données dans la table de manière efficace.

Une fois les données insérées dans la base de données PostgreSQL, nous pouvons effectuer des requêtes SQL pour analyser les données et générer des rapports à partir des données de l'INSEE. Nous avons utilisé la librairie pandas pour effectuer des requêtes SQL sur la base de données PostgreSQL et générer des rapports à partir des données de l'INSEE.